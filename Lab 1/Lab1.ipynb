{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "eeHfMzCB3hLk"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import sys\n",
        "from time import time"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Node:\n",
        "    def __init__(self, parent, state, pcost, hcost):\n",
        "        \"\"\"\n",
        "        Initializes a new instance of the Node class.\n",
        "        \n",
        "        Args:\n",
        "            parent (Node): The parent node of the current node.\n",
        "            state: The state associated with the current node.\n",
        "            pcost (float): The path cost associated with the current node.\n",
        "            hcost (float): The heuristic cost associated with the current node.\n",
        "        \"\"\"\n",
        "        self.parent = parent\n",
        "        self.state = state\n",
        "        self.pcost = pcost\n",
        "        self.hcost = hcost\n",
        "        self.cost = pcost + hcost # The total cost of the node is the sum of the path cost and heuristic cost.\n",
        "    \n",
        "    def __hash__(self):\n",
        "        \"\"\"\n",
        "        Computes a hash value for the current node.\n",
        "        \"\"\"\n",
        "        return hash(''.join(self.state.flatten())) # We flatten the state matrix and join all the elements to form a string, which is then hashed.\n",
        "    \n",
        "    def __str__(self):\n",
        "        \"\"\"\n",
        "        Returns a string representation of the current node.\n",
        "        \"\"\"\n",
        "        return str(self.state)\n",
        "    \n",
        "    def __eq__(self, other):\n",
        "        \"\"\"\n",
        "        Compares the current node with another node for equality.\n",
        "        \n",
        "        Args:\n",
        "            other (Node): The other node to compare with.\n",
        "        \"\"\"\n",
        "        return hash(''.join(self.state.flatten())) == hash(''.join(other.state.flatten())) # We compare the hash values of the flattened state matrices.\n",
        "    \n",
        "    def __ne__(self, other):\n",
        "        \"\"\"\n",
        "        Compares the current node with another node for inequality.\n",
        "        \n",
        "        Args:\n",
        "            other (Node): The other node to compare with.\n",
        "        \"\"\"\n",
        "        return hash(''.join(self.state.flatten())) != hash(''.join(other.state.flatten())) # We compare the hash values of the flattened state matrices.\n"
      ],
      "metadata": {
        "id": "eCKwR4TNGn3V"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class PriorityQueue():\n",
        "    \n",
        "    def __init__(self):\n",
        "        \"\"\"\n",
        "        Initializes a new instance of the PriorityQueue class.\n",
        "        \"\"\"\n",
        "        self.queue = []\n",
        "        \n",
        "    def push(self, node):\n",
        "        \"\"\"\n",
        "        Adds a node to the priority queue.\n",
        "        \n",
        "        Args:\n",
        "            node (Node): The node to add to the priority queue.\n",
        "        \"\"\"\n",
        "        self.queue.append(node)\n",
        "    \n",
        "    def pop(self):\n",
        "        \"\"\"\n",
        "        Removes and returns the node with the lowest cost from the priority queue.\n",
        "        \"\"\"\n",
        "        next_state = None\n",
        "        state_cost = 10**18 # Initialize state_cost to a high value.\n",
        "        index = -1\n",
        "        \n",
        "        for i in range(len(self.queue)):\n",
        "            if self.queue[i].cost < state_cost:\n",
        "                state_cost = self.queue[i].cost # Update state_cost to the cost of the current node if it's lower than the current state_cost.\n",
        "                index = i # Store the index of the node with the lowest cost so far.\n",
        "        \n",
        "        return self.queue.pop(index) # Remove and return the node with the lowest cost.\n",
        "    \n",
        "    def is_empty(self):\n",
        "        \"\"\"\n",
        "        Checks if the priority queue is empty.\n",
        "        \"\"\"\n",
        "        return len(self.queue) == 0\n",
        "    \n",
        "    def __str__(self):\n",
        "        \"\"\"\n",
        "        Returns a string representation of the priority queue.\n",
        "        \"\"\"\n",
        "        l = []\n",
        "        for i in self.queue:\n",
        "            l.append(i.state)\n",
        "        \n",
        "        return str(l)\n",
        "    \n",
        "    def __len__(self):\n",
        "        \"\"\"\n",
        "        Returns the number of nodes in the priority queue.\n",
        "        \"\"\"\n",
        "        return len(self.queue)\n"
      ],
      "metadata": {
        "id": "BKpPx-9T432L"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "class Environment():\n",
        "    \n",
        "    def __init__(self, depth=None, goal_state=None):\n",
        "        # List of possible actions: 1 - Up, 2 - Down, 3 - Right, 4 - Left\n",
        "        self.actions = [1, 2, 3, 4] \n",
        "        self.goal_state = goal_state # The state we are trying to reach\n",
        "        self.depth = depth # Maximum depth to generate the start state\n",
        "        self.start_state = self.generate_start_state() # Generate a start state\n",
        "    \n",
        "    def generate_start_state(self):\n",
        "        # This function generates a random start state with the given depth\n",
        "        \n",
        "        # Start with the goal state\n",
        "        past_state = self.goal_state\n",
        "        i = 0\n",
        "        \n",
        "        while i != self.depth:\n",
        "            new_states = self.get_next_states(past_state) # Get all possible next states\n",
        "            choice = np.random.randint(low=0, high=len(new_states)) # Choose a random next state\n",
        "            \n",
        "            if np.array_equal(new_states[choice], past_state):\n",
        "                # If the chosen state is the same as the previous state, continue\n",
        "                continue\n",
        "            \n",
        "            past_state = new_states[choice] # Set the current state to the chosen next state\n",
        "            i += 1\n",
        "            \n",
        "        return past_state # Return the generated start state\n",
        "    \n",
        "    def get_start_state(self):\n",
        "        return self.start_state # Return the generated start state\n",
        "    \n",
        "    def get_goal_state(self):\n",
        "        return self.goal_state # Return the goal state\n",
        "    \n",
        "    def get_next_states(self, state):\n",
        "        # This function returns all possible next states for a given state\n",
        "        \n",
        "        space = (0, 0)\n",
        "        for i in range(3):\n",
        "            for j in range(3):\n",
        "                if state[i, j] == '_':\n",
        "                    space = (i, j)\n",
        "                    break\n",
        "        \n",
        "        new_states = [] # List to store the possible next states\n",
        "        \n",
        "        if space[0] > 0: # Move Up\n",
        "            new_state = np.copy(state)\n",
        "            \n",
        "            val = new_state[space[0], space[1]]\n",
        "            new_state[space[0], space[1]] = new_state[space[0]-1, space[1]]\n",
        "            new_state[space[0]-1, space[1]] = val\n",
        "            \n",
        "            new_states.append(new_state)\n",
        "            \n",
        "        if space[0] < 2: # Move Down\n",
        "            new_state = np.copy(state)\n",
        "            \n",
        "            val = new_state[space[0], space[1]]\n",
        "            new_state[space[0], space[1]] = new_state[space[0]+1, space[1]]\n",
        "            new_state[space[0]+1, space[1]] = val\n",
        "            \n",
        "            new_states.append(new_state)\n",
        "        \n",
        "        if space[1] < 2: # Move Right\n",
        "            new_state = np.copy(state)\n",
        "            \n",
        "            val = new_state[space[0], space[1]]\n",
        "            new_state[space[0], space[1]] = new_state[space[0], space[1]+1]\n",
        "            new_state[space[0], space[1]+1] = val\n",
        "            \n",
        "            new_states.append(new_state)\n",
        "            \n",
        "        if space[1] > 0: # Move Left\n",
        "            new_state = np.copy(state)\n",
        "            \n",
        "            val = new_state[space[0], space[1]]\n",
        "            new_state[space[0], space[1]] = new_state[space[0], space[1]-1]\n",
        "            new_state[space[0], space[1]-1] = val\n",
        "            \n",
        "            new_states.append(new_state)\n",
        "        \n",
        "        return new_states # Return the possible next states\n",
        "    \n"
      ],
      "metadata": {
        "id": "qxLspFCo770h"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Agent:\n",
        "    \n",
        "    def __init__(self, env, heuristic):\n",
        "        self.frontier = PriorityQueue() #Initialize priority queue for nodes\n",
        "        self.explored = dict() #Dictionary to keep track of explored nodes\n",
        "        self.start_state = env.get_start_state() #Get start state from the environment\n",
        "        self.goal_state = env.get_goal_state() #Get goal state from the environment\n",
        "        self.env = env #Assign environment object to the agent\n",
        "        self.goal_node = None #Initialize goal node to None\n",
        "        self.heuristic = heuristic #Assign heuristic function to the agent\n",
        "    \n",
        "    def run(self):\n",
        "        init_node = Node(parent = None, state = self.start_state, pcost = 0, hcost=0) #Create initial node with start state, zero path cost and heuristic cost\n",
        "        self.frontier.push(init_node) #Add initial node to the frontier\n",
        "        steps = 0 #Initialize steps counter to zero\n",
        "        while not self.frontier.is_empty(): #Loop until the frontier is empty\n",
        "\n",
        "            curr_node = self.frontier.pop() #Remove and return the node with the lowest cost\n",
        "            next_states = self.env.get_next_states(curr_node.state) #Get next possible states from current node's state\n",
        "\n",
        "            if hash(curr_node) in self.explored: #If current node is already explored, skip it\n",
        "                continue\n",
        "\n",
        "            self.explored[hash(curr_node)] = curr_node #Add current node to the explored dictionary with its hash as key\n",
        "\n",
        "            if self.env.reached_goal(curr_node.state): #If current node's state is the goal state, set the goal node and break out of the loop\n",
        "                self.goal_node = curr_node\n",
        "                break\n",
        "            goal_state = self.env.get_goal_state()\n",
        "\n",
        "            for state in next_states: #Loop over the next possible states\n",
        "                hcost = self.heuristic(state, goal_state) #Calculate heuristic cost for the state\n",
        "                node = Node(parent=curr_node, state=state, pcost=curr_node.pcost+1, hcost=hcost) #Create a new node with the state, path cost and heuristic cost\n",
        "                self.frontier.push(node) #Add the new node to the frontier\n",
        "            steps += 1 #Increment the step counter\n",
        "        \n",
        "        return steps, self.soln_depth() #Return the number of steps taken and the solution depth\n",
        "\n",
        "    def soln_depth(self):\n",
        "        node = self.goal_node #Start from the goal node\n",
        "        count = 0 #Initialize counter to zero\n",
        "        while node is not None: #Loop until there are no more nodes\n",
        "            node = node.parent #Move to the parent node\n",
        "            count+=1 #Increment the counter\n",
        "        \n",
        "        return count #Return the solution depth\n",
        "    \n",
        "    def print_nodes(self):\n",
        "        node = self.goal_node #Start from the goal node\n",
        "        l = []\n",
        "        while node is not None: #Loop until there are no more nodes\n",
        "            l.append(node) #Add the node to the list\n",
        "            node = node.parent #Move to the parent node\n",
        "\n",
        "        step = 1 #Initialize step counter to one\n",
        "        for node in l[::-1]: #Loop over the nodes in reverse order\n",
        "            print(\"Step: \",step) #Print the step number\n",
        "            print(node) #Print the node\n",
        "            step+=1 #Increment the step counter\n",
        "    \n",
        "    def get_memory(self):\n",
        "        mem = len(self.frontier)*56 + len(self.explored)*56 #Calculate the memory used by the frontier and explored dictionary\n",
        "        return mem #Return the memory used\n"
      ],
      "metadata": {
        "id": "WEU6tYLaB6H_"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Heuristic 0"
      ],
      "metadata": {
        "id": "t44eIPksDPNi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def heuristic0(curr_state, goal_state):\n",
        "    return 0"
      ],
      "metadata": {
        "id": "MbMKmigDDCGc"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Heuristic 1"
      ],
      "metadata": {
        "id": "dayJ-DqYDR7C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def heuristic1(curr_state, goal_state):\n",
        "    \"\"\"\n",
        "    This function computes a heuristic value for the given current state of the puzzle\n",
        "    based on the number of misplaced tiles in the current state compared to the goal state.\n",
        "\n",
        "    Parameters:\n",
        "        curr_state (numpy.ndarray): The current state of the puzzle.\n",
        "        goal_state (numpy.ndarray): The goal state of the puzzle.\n",
        "\n",
        "    Returns:\n",
        "        count (int): The number of misplaced tiles in the current state.\n",
        "    \"\"\"\n",
        "\n",
        "    # Initialize a counter to keep track of the number of misplaced tiles.\n",
        "    count = 0\n",
        "    \n",
        "    # Loop through each cell in the puzzle grid.\n",
        "    for i in range(3):\n",
        "        for j in range(3):\n",
        "            # If the value of the current cell in the current state is not equal to the value of the\n",
        "            # corresponding cell in the goal state, then increment the counter.\n",
        "            if curr_state[i, j] != goal_state[i, j]:\n",
        "                count += 1\n",
        "    \n",
        "    # Return the final count of misplaced tiles.\n",
        "    return count\n"
      ],
      "metadata": {
        "id": "EUqTbFiSDRP0"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Heuristic 2"
      ],
      "metadata": {
        "id": "VGUJY_Z7D0gs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def heuristic2(curr_state, goal_state):\n",
        "    \"\"\"\n",
        "    This function computes a heuristic value for the given current state of the puzzle\n",
        "    based on the Manhattan distance between each tile in the current state and its\n",
        "    corresponding tile in the goal state.\n",
        "\n",
        "    Parameters:\n",
        "        curr_state (numpy.ndarray): The current state of the puzzle.\n",
        "        goal_state (numpy.ndarray): The goal state of the puzzle.\n",
        "\n",
        "    Returns:\n",
        "        dist (int): The sum of the Manhattan distances between each tile in the current\n",
        "                    state and its corresponding tile in the goal state.\n",
        "    \"\"\"\n",
        "\n",
        "    # Initialize a variable to keep track of the total Manhattan distance.\n",
        "    dist = 0\n",
        "\n",
        "    # Loop through each cell in the puzzle grid.\n",
        "    for i in range(3):\n",
        "        for j in range(3):\n",
        "            # Get the value of the current cell in the current state.\n",
        "            ele = curr_state[i, j]\n",
        "\n",
        "            # Find the indices of the same value in the goal state.\n",
        "            goal_i, goal_j = np.where(goal_state == ele)\n",
        "\n",
        "            # Calculate the Manhattan distance between the current cell and the corresponding cell in the goal state.\n",
        "            d = abs(goal_i[0] - i) + abs(goal_j[0] - j)\n",
        "\n",
        "            # Add the distance to the total distance.\n",
        "            dist += d\n",
        "    \n",
        "    # Return the final sum of Manhattan distances.\n",
        "    return dist\n"
      ],
      "metadata": {
        "id": "h_eOl02fDy6q"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Define the depth of the search tree.\n",
        "depth = 500\n",
        "\n",
        "# Define the goal state of the puzzle.\n",
        "goal_state = np.array([[1, 2, 3], [8, '_', 4], [7, 6, 5]])\n",
        "\n",
        "# Create a new environment with the specified depth and goal state.\n",
        "env = Environment(depth, goal_state)\n",
        "\n",
        "# Print the start state of the puzzle.\n",
        "print(\"Start State:\")\n",
        "print(env.get_start_state())\n",
        "\n",
        "# Print the goal state of the puzzle.\n",
        "print(\"Goal State:\")\n",
        "print(goal_state)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nizJu6XMEJ53",
        "outputId": "cb2e1c7b-ebd3-4657-9764-899c07eb5ed0"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Start State:\n",
            "[['8' '3' '1']\n",
            " ['6' '4' '7']\n",
            " ['2' '5' '_']]\n",
            "Goal State:\n",
            "[['1' '2' '3']\n",
            " ['8' '_' '4']\n",
            " ['7' '6' '5']]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "agent = Agent(env = env, heuristic = heuristic2)\n"
      ],
      "metadata": {
        "id": "XbLLkAQqEV3I"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "depths = np.arange(0,501,50)\n",
        "goal_state = np.array([[1,2,3], [8,'_',4], [7,6,5]])\n",
        "times_taken = {}\n",
        "mems = {}\n",
        "for depth in depths:\n",
        "    \n",
        "    time_taken = 0\n",
        "    mem = 0\n",
        "    for i in range(50):\n",
        "        env = Environment(depth=depth, goal_state=goal_state)\n",
        "        agent = Agent(env = env, heuristic = heuristic2)\n",
        "        start_time = time()\n",
        "        end_time = time()\n",
        "        time_taken+=end_time - start_time\n",
        "        mem+=agent.get_memory()\n",
        "    \n",
        "    time_taken/=50\n",
        "    mem = mem/50\n",
        "    times_taken[depth] = time_taken\n",
        "    mems[depth] = mem\n",
        "    print(depth, time_taken, mem)\n",
        "\n",
        "    "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xoKOiDYiEec7",
        "outputId": "0c2d0bde-908c-4b60-f6e5-aa2f8d85a687"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 1.811981201171875e-07 0.0\n",
            "50 5.769729614257812e-07 0.0\n",
            "100 3.6716461181640626e-07 0.0\n",
            "150 2.86102294921875e-07 0.0\n",
            "200 3.3855438232421873e-07 0.0\n",
            "250 3.290176391601562e-07 0.0\n",
            "300 3.5762786865234375e-07 0.0\n",
            "350 3.337860107421875e-07 0.0\n",
            "400 3.1948089599609377e-07 0.0\n",
            "450 4.38690185546875e-07 0.0\n",
            "500 3.9577484130859373e-07 0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UKysU7J9EjfO"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}